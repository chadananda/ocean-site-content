---
url: https://bahai-library.com/hatcher_foundations_mathematics
title: Foundations of Mathematics: An Overview at the Close of the Second Millennium
audio: 
author: William S. Hatcher
image: https://bahai-library.com/images/h/hatcher_foundations_figure1.gif
source: Converging Realities, 1:1
date: 2000
doctype: website
status: search-only
encumbered: false
collection: Published Articles (bahai-library.com)
collectionImage: 
---


## Foundations of Mathematics: An Overview at the Close of the Second Millennium

### by [William S. Hatcher](https://bahai-library.com/author/William+S.+Hatcher)

published in Converging Realities, 1:1  
Switzerland: Landegg Academy, 2000


| **Contents**
**1\. The Basic Issues**

1.1 The abstract nature of mathematics  
1.2 The Special Status of Mathematical Knowledge  
1.3 Logic and Mathematics

**2\. The Axiomatic Method and its Origin**

2.1 Euclid's Element  
2.2 Multiple Interpretations, Consistency, and Abstract Axiomatics

**3\. Foundational Systems**

3.1 The Emergence of Modern Mathematical Analysis  
3.2 The Arithmetization of Analysis  
3.3 Dedekind and the Axiomatization of Arithmetic  
3.4 Frege's System and the Paradoxes  
3.5 Type Theory and Set Theory  
3.6 Foundational Aspects of Set Theory  
3.7 Constructivism and Predicativity  
3.8 Combinatory Logic and Category Theory  
3.9 The Current Situation: Comparative and Pluralistic Foundations

**Bibliography**

 |

* * *

> **Abstract:** An intellectual tradition extending back at least to the time of Plato attributes various special qualities to mathematical knowledge. Within this tradition, mathematics may be viewed, for example, as more exact, certain, objective, universal, abstract, formal, or useful than other kinds of knowledge. The study of the foundations of mathematics examines the origin or genesis of mathematical ideas and methods, as well as the structure and organization of the mathematical corpus, primarily with the goal of understanding, explaining, or justifying the perceived special qualities of mathematical knowledge.
> 
> Thus, in foundations, mathematics itself becomes the object of study. So conceived, foundational studies are partly philosophical and partly technical (mathematical).
> 
> Although the study of mathematical foundations has always been a recognizable part of mathematics and philosophy, it is only since about 1900 that foundational study has emerged as a relatively independent discipline with its own methods, techniques and goals. These modern developments have witnessed a sharpening of the philosophical issues relating to mathematics as well as a refinement of the techniques and methods used in foundational study. The present article will therefore concentrate on the modern period, but give sufficient historical background to allow for an adequate understanding of modern developments.  
>   
> This article was commissioned by _The Encyclopaedia Britannica,_ which subsequently ceded copyright to the author.

* * *

### 1\. The Basic Issues

  
The question of what it means to know mathematically is clearly a part of the larger philosophical question of what it means to know generally. Foundational study therefore seeks to understand both the intrinsic nature of mathematics and the status and role of mathematics within the overall scientific and philosophical enterprise.

**1.1 The abstract nature of mathematics**

Mathematics is traditionally conceived as the science of space (geometry) and of quantity (arithmetic). Empirical observation is thus an obvious source of many mathematical ideas (put one apple together with another, and we have in fact two apples). However, mathematics itself proceeds by the contemplation and study of abstract (nonphysical), ideal entities, that is, entities that have no exact counterpart in observable, physical reality (e.g., the infinite and perfectly regular lines and planes of Euclid's geometry). A basic concern of foundational study is to determine the nature of these entities and the extent to which it is legitimate to attribute objective existence to them.

Three classic schools of foundational study arise from three possible answers to this question. _Platonism_ or _realism_ holds that mathematical entities have objective existence on a par with other such mind-independent entities as stones and stars. In this view, mathematical knowledge is the knowledge of these mathematical entities, a knowledge that is discovered but not invented by the human mind. _Intuitionism_ or _constructivism_ holds that the ideal objects of mathematics exist only within the human mind, arising as mental constructions based on our observation of physical approximations to the ideal. Mathematical knowledge is therefore viewed as partly discovered (through observation) and partly invented by creative intellectual acts. _Formalism_ or _nominalism_ holds that the objects of mathematics have no existence whatsoever but are only helpful mental fictions that enable us to generate certain useful, though purely conventional, rules for the manipulation of symbols in various contexts. We may have used these rules implicitly and intuitively before formulating them explicitly. Their explicit formulation is the _formalization_ of mathematics.

Everyone agrees that mathematical activity involves all three processes: the contemplation of abstractions, the generation of mental constructions, and the explicit formulation of rules for symbolic manipulation. The philosophical differences arise when we consider the question of the relative status of these activities and the extent to which they comprise all or part of mathematics.

**1.2 The Special Status of Mathematical Knowledge**

Each of the three basic philosophies of foundations has its own characteristic explanation of the perceived special qualities of mathematical knowledge. For example, Platonists would ascribe mathematical certainty and exactness to the stability of mathematical objects, which are held to be nonphysical, absolute, and unchanging. In contrast, empirical knowledge is less certain or exact because the physical world is in a state of continual flux. Intuitionists would tend to attribute mathematical certainty and exactness to the degree of control we exert over mathematical objects: since they are explicit constructions of our minds, we can manipulate them freely and know them certainly. In this view, mathematics is exact because it contains only what we deliberately put into it. Formalists would hold that mathematical certainty and exactness derive from the formal and explicit character of mathematical rules. For the pure formalist, the goal is always complete formalization, which achieves total objectivity in that formal rules can, in principle, be executed by a machine that is utterly devoid of human subjectivity and its vagaries.

**1.3 Logic and Mathematics**

Basic to foundational study is the central role that (deductive) logic has played in the development, organization and articulation of mathematics. Some, for example the French structuralist school of N. Bourbaki, consider the most distinctive feature of mathematics to be the extent and manner that mathematics uses deductive logic. Others (e.g., Bertrand Russell) have gone further and proposed a mathematical _logicism,_ which holds that mathematics is (or reduces to) logic.

In opposition to this are mathematicians (e.g., Ren√© Thom) who have insisted that (geometrical) intuition is the most fundamental aspect of mathematical activity. But even those mathematicians who give great value to intuition recognize that logic is an inextricable aspect of mathematical activity. Indeed, logical methods have often succeeded in validating mathematical principles that appeared quite unnatural intuitively.

_Computability theory_ or _algorithmics_ is a limited but extremely useful expression of deductive logic in mathematics. An _algorithm_ (the term is derived from the name of the ninth century Arabic mathematician Al-Khwarizmi) is a finite set of instructions that can be carried out mechanically in a finite number of discrete steps. Modern computability theory is based on a precise, mathematical formulation of the notion of an algorithm, first developed by the English mathematician A. Turing in the 1930s.

The programmed instructions that drive electronic computing devices are examples of algorithms, and the increasing sophistication and availability of these computers has considerably enhanced the status of computability theory, making it one of the most active branches of contemporary mathematics. Pure formalists (and some constructivists) would hold that abstract mathematics in general, and deductive logic in particular, are truly useful only when they yield algorithms.

In any case, the special role that deductive logic plays in mathematics has given rise to a particular method that may be said to characterize mathematics.

**2\. The Axiomatic Method and Its Origins**

Logic and reason have played a major role not only in mathematics but also in science and in discursive philosophy. However, there are important differences between the way mathematics uses logical techniques and the way other disciplines use them.

The empirical (or natural) sciences make equal use of both deductive logic, which is a movement of thought from general to particular (analysis), and inductive logic, which is a movement of thought from particular to general (synthesis), proceeding by an alternation of inductive and deductive moves. Induction is used to establish certain general principles that then form the basis for chains of deduction. It is usually rare to encounter extremely long chains of deductive reasoning in the empirical sciences, especially in the early stages of their development.

Long deductive chains are also rare in traditional philosophy. This is because the more _a priori_ method of philosophy (particularly metaphysics) tends to multiply the philosophical assumptions, thereby reducing the necessity of engaging in long chains of pure deduction. The philosopher more naturally dedicates his efforts to finding and justifying the underlying principles of his subject than to the technical task of generating extensive and complex deductive chains (though this has changed somewhat in the modern period, primarily due to the influence of mathematics on philosophy).

However, it is characteristic of mathematics that deduction takes priority over induction, that extremely long deductive chains are used, and that the initial assumptions are reduced to the barest minimum rather than multiplied. Thus, it is principally to mathematics that we owe the _axiomatic method,_ which consists in organizing a large body of knowledge by explicitly deducing every single proposition from a few explicitly designated assumptions. The assumed propositions are called _axioms_ and the deduced (or derived) propositions _theorems._ According to the axiomatic method, inductive logic is relegated to a purely informal use. It may serve to suggest to the mathematician that a certain proposition is true and therefore potentially deducible from the axioms, but the proposition will be accepted as justified only when an explicit deduction of it has been given (or shown to exist), never on the basis of informal, inductive reasoning alone. Moreover, the axiomatic method deliberately seeks an economy of thought, and does not countenance the easy multiplication of assumptions in the manner of philosophy. In particular, if it is discovered that a given axiom p can be deduced from the other axioms, then the proposition  p  becomes a proved theorem and is deleted from the set of axioms.

Thus, an _axiomatic system_ **_S_** has at least the five constituents

(_L, P, Ax, R, Th_), where _L_ is an explicitly formulated language, _P_ is a collection of propositions (statements) of _L_, _Ax_ is the collection of assumed propositions, _R_ the deductive rules, and _Th_ the derived propositions. A deductive chain (or proof) in **_S_** is an ordered list  
_p1, p2, . . . , pn_ of propositions such that each proposition in the list (each _line_ of the proof) is either an axiom or else derived from previous propositions of the list according to the rules _R_. A theorem _t_ is precisely a proposition of _L_ for which there exists a deductive chain (derivation) _p1, p2, . . . , pn_ = _t,_ ending with _t._ Notice that every axiom _p_ is a theorem, for which _p_ is a one-line proof of itself.

Because the rules and principles _R_ of deductive logic preserve propositional truth, all theorems _Th_ of an axiom system **_S_** are true if the axioms _Ax_ of _**S**_ are true. Thus, when once the axioms of a system **_S_** have been verified to be true, the verification that a proposition _p_ of _L_ has a valid proof in _**S**_ also constitutes a verification that _p_ is true. (However, a proposition _p_ of _L_ can be true without having a valid deduction from the particular axioms of _**S**._)

To validate or verify a proof _p1, p2, . . . , pn_ in **_S_** means to go through the proof step by step and ascertain that each line _pi_ does indeed follow from the previous lines _p1, p2, . . . , pi-1_ according to the deductive rules and principles _R._ Usually the rules _R_ of logic are formulated in such a way that checking any given step in a deductive chain is a simple matter. Thus, finding a valid proof is a highly creative and possibly quite difficult task (and one for which there are, in general, no rules) but verifying that a purported proof is indeed valid is, in principle, an easy, rule-based task (though possibly tedious and time-consuming).

Typically, a well-developed axiomatic system is extremely complex, containing thousands of known and validated theorems. But any question of the truth of any of these theorems reduces to the question of the truth of the axioms on which they ultimately depend. Thus, the organization of knowledge into an axiomatic system puts the burden of truth on the axioms of the system, rather than distributing the truth burden throughout the body of knowledge as with natural science and philosophy.

This feature of the axiomatic method is one of the main justifications for the immense effort and time mathematicians invest in the search for deductive proofs. Another reason is the following: since the truth of the axioms implies the truth of the theorems, the falsity of even one theorem implies the falsity of at least one of the axioms. Of course, when the assumed propositions of a system _**S**_ are sufficiently simple to be obviously true, there is no problem. But, the more powerful the axioms, the more complex and abstract they tend to be, often making them neither obviously true nor obviously false. When this is the case, then one way of detecting their falsity is to exhibit an obviously valid proof of an obviously false theorem. In this way, extensive deduction serves both as an enrichment of a true axiom system and as a protection against a false one.

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

**Figure 1. Constituents of an axiomatic system _S_**  

![](https://bahai-library.com/images/h/hatcher_foundations_figure1.gif)

The collection _P_ of all propositions of the language _L_ contains the subcollection _Th_ of all theorems. Each theorem _t_ is deduced from the further subcollection _Ax_ of all axioms by a finite number of applications _p1, p2, . . . , pn = t_ of the rules _R_.

Since the rules _R_ preserve truth, the theorems _Th_ are all true if all of the axioms _Ax_ are true. Thus, if any theorem _t_ is false, then at least one of the axioms is also false, and the set _Ax_ of axioms is then inconsistent, i.e., has no model (see below).

One frequently studies different systems _**S**_ with the same language and deductive rules but with different sets of axioms. In this case, we refer to the logical rules as the _underlying logic_ of these systems.

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

Although the axiomatic method has been used and applied outside of mathematics, it originated within mathematics and has been carried to a much higher development in mathematics than elsewhere. It can thus be seen as one of the most distinguishing features of mathematics. The axiomatic method also accounts for some of the perceived special qualities of mathematical knowledge including certainty and exactness.  

**2.1 Euclid's Elements**

Historically, geometry was the first mathematical discipline to be successfully organized as an axiomatic system. Accomplished by Euclid in the fourth century B. C., this achievement was and is astonishing for a number of reasons. To begin with, one would have thought that arithmetic, with its rule-like behaviour, would be a more likely candidate for early axiomatization. Yet arithmetic was not successfully axiomatized until the work of Richard Dedekind in the late nineteenth century (see below).

Geometry codifies our intuition of spatial relationships, an intuition that does not appear to lend itself easily to the formulation of exact rules or relationships. Even to conceive of the possibility of axiomatizing geometry was bold enough, but to have accomplished the task in one lifetime is breathtaking. Moreover, the system of Euclid's _Elements_ is so sophisticated that no substantial improvement was made in it until the work of M. Pasch and D. Hilbert in the late nineteenth century. Thus, Euclid's work became the unsurpassed canon of the axiomatic method for more than two thousand years.  

**2.2 Multiple Interpretation, Consistency and Abstact Axiomatics**

Even though Euclid's geometry remained essentially unmodified until the modern period, there was nonetheless a certain evolution in the conception of the axiomatic method itself. This evolution was due to the gradual realization that a given set of axioms could be valid under several different interpretations, i.e., that axioms, if appropriately interpreted, could be equally true of different realities. To see this, consider the following true proposition of Euclidian plane geometry:

(A) Any line is completely determined by any two non-identical points that lie on the line.

The proposition _A_ has the following general form: "Any object _x_ of type _Ln_ is completely determined by any two objects _y_ and _z_ of type _Pt_ that are not in the relation _Id_ and that bear the relation _Ot_ to _x._" Now, let us reinterpret the types and relations _Ln, Pt, Id_ and _Ot_ as follows: _Ln_ is now the category (type) 'point', _Pt_ is now the type 'line', _Id_ is now the relation 'parallel' and _Ot_ is the relationship 'passes through'. Under this interpretation, proposition _A_ now become proposition _B_: "Any point _x_ is completely determined by any two lines _y_ and _z_ that are nonparallel and that pass through the point _x_." The proposition _B_ is also true in Euclidean plane geometry though the meaning of _A_ and _B_ are quite different. Yet _A_ and _B_ "have the same form" in that we have reinterpreted only the specific types and relations. We say that we have reinterpreted the _non-logical_ (or _specific_ ) parts of _A_ and that we have maintained or preserved its _logical_ (or _general_ ) parts (e.g., such terms as 'any', 'object', 'type', 'completely determined', 'not' or 'two'.)

Let us consider yet another interpretation: _Pt_ means 'human zygote', _Ln_ means 'human gamete', _Id_ means 'same sex', and _Ot_ means 'sexually generated'. Under this interpretation, _A_ now means _C_: "Any human zygote _x_ is completely determined by any two human gametes _y_ and _z_ of the opposite sex that have sexually generated _x_."

Again, _C_ is true, but of a completely different reality, having nothing to do with geometry. Thus, under the appropriate interpretation of its nonlogical parts, the same statement _A_ is true of three different realities. However, these three realities can be distinguished by other properties. For example, there is not a unique pair of distinct points that determine a given line (or a unique pair of nonparallel lines that determine a given point), but every human zygote is determined by only one pair of gametes. However, points and lines do not share all the same properties either. For example, a plane can be passed by any three points, but a plane cannot be passed through any three lines.

We have given examples of reinterpretations that preserve truth, but clearly many reinterpretations will be false. For example, under the first interpretation just reinterpret the category _Ln_ as 'point', (keeping the other types and relations unchanged) and the resulting statement is false. Indeed, arbitrary reinterpretations are more likely to be false than true. We now summarize the points illustrated by this example:

1\. The specific terms (types and relations) of a statement can be reinterpreted without changing the (syntactical) form or structure of the statement with respect to its purely logical parts.

2\. The statement may be true under some of these reinterpretations and false under others.

Any interpretation of the specific terms of a set _Ax_ of axioms which makes all of the axioms true is said to be a _model_ of the axioms. A set of axioms is _consistent_ if it has at least one model. It is _universally valid_ if true under all possible interpretations of its specific terms.

Now, the rules _R_ of deductive logic are _formal_ in that they preserve the syntactical form (logical structure) of propositions, and in such a way that all of the theorems _Th_ of an axiomatic system **_S_** are true in any model of the axioms _Ax_ of **_S_**. Moreover, for _first-order_ systems (systems based on a wide class of so-called first-order languages), the rules of deductive logic are _complete_ in the precise sense that a formal logical contradiction (a proposition of the form "_p_ and not![](https://bahai-library.com/images/h/hatcher_foundations_Image115.gif)-_p_") can be deduced from any inconsistent set of axioms (i.e., any set of axioms that has no model). The converse also holds, since any statement of the form "_p_ and not![](https://bahai-library.com/images/h/hatcher_foundations_Image115.gif)-_p_" is false under every interpretation of _p_ (i.e., every interpretation that preserves the meaning of the logical terms 'and' and 'not'). Thus, if a formal contradiction _t_ is provable as a theorem of a system **_S_**, then the axioms of _**S**_ are false under any interpretation and hence have no model. In other words: the axioms _Ax_ of a first-order system **_S_**are inconsistent (have no model) if and only if a formal contradiction "_p_ and not![](https://bahai-library.com/images/h/hatcher_foundations_Image115.gif)-_p_" is provable as a theorem of _**S**._

It follows from the above that, for first-order systems, the consistency of a given set of propositions does not depend on the meaning of the specific terms in the propositions; it depends only on the form or structure of the propositions with regard to their logical parts. Moreover, formal deduction alone can be relied upon to detect inconsistency.

According to the logical rules of most systems (and first-order systems in particular), any proposition _q_ can be deduced from a formal contradiction. Thus, a further property of an inconsistent system **_S_** is that every proposition of **_S_** is a theorem of _**S**_. In other words, anything whatsoever can be proved in an inconsistent system.

These results on logic, which have only been achieved in the twentieth century, have allowed for a much more general form of the axiomatic method, called the _abstract_ (or _formal_ ) axiomatic method. This method consists in leaving the specific terms of an axiomatic system uninterpreted (or "undefined") from the beginning. The only requirement is that the axioms be consistent, and thus true of some reality, but we no longer require that this reality be specified. In the formal axiomatic method, the role previously played by truth is now played by consistency, and consistency depends only on the syntactical form of the axioms with respect to their logical parts, not on their specific content (meaning) under a given interpretation.

Thus, the same abstract axiomatic system **_S_** may be used to study concrete, existing realities and also abstract, logically possible realities. The abstract axiomatic method thereby gives enormous power and flexibility to mathematics, allowing us to apply (by reinterpretation) the same system _**S**_ (the same body of mathematical results) in many different contexts. For example, it may turn out that the mathematical theory, say, of languages, of genetics and of machine computation is essentially the same. In such a case, each theorem _t_ of our system **_S_** will have an interpretation as a true proposition in each of the respective models.

The abstract axiomatic method also allows us to sharpen our understanding of the nature and status of mathematics within the overall scientific enterprise. At one extreme, the natural sciences study concrete realities that actually exist (or that may exist under given physical conditions). At the other extreme, pure logic studies all possibly existing realities, whether abstract or concrete, actually existing or not. Mathematics lies between these extremes. It studies both concrete and abstract realities. However, mathematics (it is now generally agreed) is not pure logic. Mathematics is not interested in all possibly existing structures, because many of these structures are _useless_ to us (for many different reason, e.g., triviality or gratuitous complexity). Thus, we may sum up the relationship between mathematics and logic by saying that logic has general content but no specific content, while mathematics has both general (logical) content and specific content (e.g., truths about spatial relationships or numerical calculations).

The criterion of usefulness gives a certain pragmatic, normative aspect to mathematical activity. Mathematics tries to solve real problems by providing useful theories of these problems in appropriate axiomatic systems. The mathematician does not, therefore, waste time exploring systems that are arbitrary or that seem to hold no promise of solving the problems at hand. Such systems may be explored by philosophy, and perhaps with no initial motivation beyond idle curiosity, but the mathematician will examine them only when he or she has some reason to believe they will be useful in solving mathematical problems.

Finally, the foundational study of mathematics explores those structures or realities that are relevant to solving _foundational problems_, that is, those problems relating to the genesis and nature of mathematics itself. The systems used to study foundational problems are called _foundational systems._ These are abstract axiomatic systems of great power and generality, which contain many branches of mathematics as subsystems. We want now to examine the major foundational systems that have appeared in the modern period.

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

**The historical origin of multiple interpretation and thus of the abstract axiomatic method was the appearance of non-Euclidean geometries in the nineteenth century.**

1\. Euclidean geometry

In Euclidean plane geometry, \[1\] any two distinct points determine a unique line and \[2\] any two different, intersecting lines determine a unique point. _Hyperbolic_ and _parabolic_ geometry maintain these properties, but differ from Euclidean geometry with respect to a third property: According to Euclid's axioms, \[3\] one and only one line _L_' that does not intersect a given line _L_ can be drawn through any given point _P_ exterior to _L._

2\. Hyperbolic geometry

In hyperbolic plane geometry, the notions "point", "line" and "plane" are reinterpreted as follows: The plane is no longer infinite in extent, but consists of the interior of a fixed circle _C_. Thus, the points of hyperbolic geometry are those Euclidean points that lie inside the circle _C_. Hyperbolic lines are the chords _AB_ of _C_, excluding the endpoints _A_ and _B_ (which lie on the circle and thus outside the plane). Under this interpretation, there are many lines _L_' and _L_'' that may pass by a point _P_, exterior to a given line _L_, without intersecting _L_. But this system satisfies \[1\] and \[2\] and, indeed, all the other axioms of Euclidean geometry except \[3\].

**Figure 2. Hyperbolic Lines**  

![](https://bahai-library.com/images/h/hatcher_foundations_figure2.gif)

Hyperbolic geometry was first discovered (independently) by the Hungarian J. Bolyai and the Russian N. I. Lobachevsky (c. 1825).

2\. Parabolic geometry

In parabolic geometry, some particular point p in Euclidean three-dimensional space is chosen. The parabolic plane is then the set of all Euclidean lines through _p,_ and a parabolic line is a Euclidean plane containing the point _p_. Since the intersection of any two distinct Euclidean planes is a line, the intersection of any two distinct parabolic lines ![](https://bahai-library.com/images/h/hatcher_foundations_Image82b.gif)and![](https://bahai-library.com/images/h/hatcher_foundations_Image82b.gif)' will be a parabolic point _L_ (i.e., a Euclidean line through p). Also, any two distinct parabolic points l and l' will determine a unique parabolic line ![](https://bahai-library.com/images/h/hatcher_foundations_Image82b.gif)(i.e., a Euclidean plane ![](https://bahai-library.com/images/h/hatcher_foundations_Image82b.gif)containing _p_). Parabolic geometry thus satisfies \[1\] and \[2\].

However, in parabolic geometry, any two parabolic lines ![](https://bahai-library.com/images/h/hatcher_foundations_Image82b.gif)and ![](https://bahai-library.com/images/h/hatcher_foundations_Image82b.gif)'; will intersect (since both must contain the point p). Thus, in parabolic geometry, no line whatever can be drawn that does not intersect a given line ![](https://bahai-library.com/images/h/hatcher_foundations_Image82b.gif). Hence \[3\] fails in parabolic geometry but in a different way than in hyperbolic geometry. Also, as with hyperbolic geometry, parabolic geometry satisfies all of the other axioms of Euclidean plane geometry except \[3\].

**Figure 3. Lines in Parabolic Geometry**  
![](https://bahai-library.com/images/h/hatcher_foundations_figure3.gif)

Parabolic geometry originated with B. Riemann in 1848, and was part of a comprehensive treatment of geometry that included parabolic, hyperbolic and Euclidean geometry as special cases.

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

**3\. Foundational Systems**

It has taken several thousand years for the axiomatic method to evolve and develop into its current form, which has become the primary technique of modern foundational study. However, parallel to the evolution of the methods of mathematics was a similar evolution of its content. We need to sketch the latter before undertaking a direct discussion of the principal modern foundational systems.

**3.1 The Emergence of Modern Mathematical Analysis**

Though the Egyptians, the Sumerians, the Babylonians and the Chinese all developed various rudimentary mathematical systems dealing either with geometry or arithmetic, the efflorescence of ancient Greece (roughly the period 500-300 B.C. of the Athenian city-state) represents without doubt the summit of premodern mathematical (and philosophical) development. The Greeks saw all of mathematics through the prism of geometry. Numbers represented geometrically defined quantities such as lengths, areas or volumes, and the manipulation of numbers was primarily through geometrical constructions.

The manipulation of numbers as pure quantities derives not from the Greeks but from the Indic and Arabic cultures. The name _algebra_ eventually given to the discipline that codifies and axiomatizes the rules for these manipulations derives from the title of the book _Al-Jabr_ published in the ninth century by the Muslim mathematician Al-Khwarizmi.

Modern mathematics owes to the Indic-Arabic cultures at least two outstanding contributions. The first is the highly flexible number system based on positional or place value, which uses only a finite number of ciphers (digits) to give a unique numeral (name) for each member of the infinite set **_N_**of _natural numbers_ (the _nonnegative integers_ 0, 1, 2, . . .). Each numeral is itself a finite list of ciphers in which the value of each cipher c is multiplied, according to its position in the list, by an appropriate power of a fixed base **_b_**. Because the base **_b_** was most often given the value ten, the system of positional value has become popularly known as the _decimal_ system, but **_b_** can in fact be given any fixed value greater than one.

The system of place value leads to highly efficient algorithms (see above) for the four arithmetic operations of addition, multiplication, subtraction, and division (and for other operations as well); whereas, systems not based on place value (e.g., the well-known system of Roman numerals) do not seem to allow for algorithms of comparable power and efficiency. Indeed, so sophisticated and flexible is the system of Arabic numerals that no significant modification of it has been necessary even for modern computers, which are constructed on a binary system of place value and whose programmed computations are based directly on the algorithms generated by the Arabic system.

The Greeks studied the system _**P**_ of _positive integers_ 1, 2, 3, . . . , which is just the system **_N_** without 0. However, enumeration by positional value makes unavoidable and essential use of 0. Thus, although the Greeks did succeed in devising some effective algorithms (e.g., the well-known algorithm devised by Euclid to find the greatest common divisor of two given positive integers), they never elaborated a number system as such, and their approach to arithmetic remained heavily geometrical: the sequence 1, 2, 3 . . . of positive integers was viewed as the end-to-end repetition, along a fixed axis, of a unit line segment of fixed length. Since a line segment cannot have zero length, it is easy to understand why the Greeks omitted 0 from their number system and thereby failed to devise a system of positional value.

The second major Arabic contribution to mathematics was the development and codification of rules and techniques for manipulating numbers together with _variables_ or _indeterminates,_ that is, non-numerical symbols _xi_ standing for arbitrary numbers (called the _values_ of the variables). An expression _P_(_x1_, . . ., _xn_) involving both numerals (called the _constants_ or the _coefficients_ of the expression) and variables _x1_, . . ., _xn,_ which are added, multiplied or subtracted, is now called a _polynomial_. Many practical (and even theoretical) problems of mathematics can be resolved by finding those values _a1_, . . ., _an_ of the respective variables _x1_, . . ., _xn_ that reduce to zero the expression _P_(_a1_, . . ., _an_), obtained from _P_(_x1_, . . ., _xn_) by replacing each variable _xi_ by the corresponding value _ai_ and applying the operations of the expression to these substituted values. In this case, we say that the list of values _a1_, . . ., _an_ are _zeroes_ or _roots_ of the polynomial and we write: _P_(_a1_, . . ., _an_) = 0\. We also say that the list _a1_, . . ., _an_ constitutes a _solution_ of the polynomial equation _P_(_x1_, . . ., _xn_) = 0\. (By subtraction, any equation _P_ = _Q_ between two polynomials is logically equivalent to the simpler form _P_ - _Q_ = 0, since the difference _P_ - _Q_ of two polynomials is also a polynomial).

Even though the coefficients of a polynomial are natural numbers, the solutions do not have to be natural numbers. For example, the solution to the equation 3_x_-2 = 0 is 2/3, which is a rational fraction (ratio of two integers). Similarly, solutions to the equations _x_\+ 2 = 0, _x_2\- 2 = 0, and _x_2 \+ 1 = 0 include, respectively, the negative integer -2, the irrational number ![](https://bahai-library.com/images/h/hatcher_foundations_Image83b.gif), and the imaginary number _i_ = ![](https://bahai-library.com/images/h/hatcher_foundations_Image84.gif). (Of course, the search for zeroes of a polynomial can be deliberately restricted to integer solutions. In that case, we speak of a _diophantine equation._)

Thus, the search for solutions to polynomial equations with natural number coefficients leads naturally to a wider class of numbers, the algebraic numbers. In modern terms, the _algebraic numbers_ are precisely those numbers that can occur as roots of some polynomial _P_(_x_), in a single variable _x_ and with natural number coefficients. In a somewhat restrictive sense of the term, _algebra_ can be considered the discipline that has, as its principal object of study, the algebraic numbers.

Just as the natural numbers themselves can be codified by the Arabic numeral system of place value, so the algebraic numbers can be codified or named by the polynomials of which they are roots. Indeed, a numeral in the Arabic system is precisely a "one-variable polynomial" in which the base **_b_** is substituted for the variable _x_.

When algebraic numbers are added, multiplied, subtracted or divided (except by zero) the result is always an algebraic number. We say that the algebraic numbers are _closed_ under each of the four basic operations of arithmetic. In modern mathematics, any system closed under these operations is called a _field._ Though the algebraic numbers constitute a particularly natural field, there are in fact many fields. For example, the _rational numbers_ **_Q_** (those numbers expressible as a ratio of two integers) and the _real numbers **R**_  (those not involving the imaginary number i) also constitute a field. Nonalgebraic reals are _transcendental_ and nonrational reals are _irrational._ Since all rationals are algebraic, all transcendentals are irrational.

The degree to which geometry and algebra evolved independently of each other is initially surprising, but is probably due to the fundamental difference in the nature of the respective intuitions that generate them. Geometric intuition is synthetic and continuous, perceiving configurations as completed wholes endowed with various global regularities. Algebraic intuition is analytic and discrete, perceiving global structures as built up by the accretion of distinct quanta, gradually extending local regularities. The beginning of modern mathematics was the fusion of these two intuitions into a single discipline: _algebraic geometry._ This was accomplished in the seventeenth century by the consummate French philosopher and mathematician Ren√© Descartes.

The Greeks had already observed that geometrical figures, though continuous, can nonetheless be considered as sets of points. For example, a circle of radius one is the _locus_ (set) of precisely those points having a fixed distance of one unit from a given fixed point (the center of the circle). Building on this notion, Descartes' method consisted in establishing a correspondence between points and numbers and thus between sets of numbers and geometrical figures (loci). Along a given axis (Euclidean line), each point corresponds to one, distinct real number (algebraic or transcendental). Since a line is one-dimensional, the field of real numbers has a dimension of one (a single number, which corresponds to a point, has dimension zero). The two-dimensional Euclidean plane can be algebraically encoded as pairs of numbers, by taking two axes perpendicular to each other. The generalization to three, and thus to arbitrary finite dimensions is obvious.

In this way, the set of zeroes of a polynomial _P_(_x1_, . . ., _xn_) in n distinct variables determines a set of points ‚Äî thus a geometrical figure ‚Äî in n-dimensional Euclidean (Cartesian) space. For example, the set of pairs (_x,y_) of numbers satisfying the polynomial equation:  
_x_2 \+ _y_2 \- 1 = 0 corresponds precisely to a circle of radius one, centered at the origin (the intersection of the axes in the plane).

We generalize by allowing real numbers not only as values of variables but also as coefficients in polynomials. Now, for example, every line in the plane has one and only one equation of the form _ax_+_by_+_c_ = 0, where the coefficients _a,b_ and _c_ are real numbers.

Descartes' fusion of geometry and algebra was not only elegant but also extremely fertile for both disciplines. On the one hand, geometrical intuition could be applied to what were previously purely abstract expressions, while on the other hand, the algorithmic and discrete methods of algebra allowed for a quantizing of space.

Within one generation after Descartes' fundamental advance, the unified science of _mathematical analysis_ was born though the simultaneous and independent discovery of the calculus by Newton in England and Leibniz on the continent. In trying to understand the transition from algebraic geometry to analysis, observe that the algebra inherited from the Arabs consisted of finitary operations on finite quantities. Newton's approach to the calculus was to add an infinitary operation ‚Äî _the limit._ Thus, the infinite sum:  
1 + 1/2 + 1/4 + . . . + 1/2n \+ . . . can be defined to have the limit 2, even though this value is never actually attained directly as a finite sum of values. Leibniz' approach was to maintain finitary operations but to introduce infinitely small (infinitesimal) and infinitely large quantities, extending the real number field **_R_** to a hyperreal field **_R_***. The complete equivalence of these two approaches was definitively established only in 1960 by Abraham Robinson and constitutes one of the major results of modern foundational studies.

The power of the calculus is that it allows for an analytic study of dynamic processes. Such processes are represented by _functions,_ that is, operations f that associate exactly one value _f_(_x_) to each argument (object) _x_ chosen from a given set _X_. We say that _f_(_x_) represents the application of the function _f_ to its argument _x_. Functions are often symbolized as _f:X Y_, where _f_ is the operation, _X_ is the given set of arguments, and _Y_ is the set of possible values of _f._ Functions of this type could represent, for example, temperatures _f_(_t_) = _r_, recorded at different moments of time _t_ or the area _A_ = _f_(_d_) of a circle having diameter _d_.

Also, the action of two functions _f_:_X![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)Y_ and _g_:_W![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)X_ can be combined by the operation of functional composition√∂ to form a new function _h_:_W![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)Y, h_ = _g![](https://bahai-library.com/images/h/hatcher_foundations_Image95.gif)f_, whose action on any argument w in the set W is defined by _g![](https://bahai-library.com/images/h/hatcher_foundations_Image95.gif)f_(_w_) = _g_(_f_(_w_)). Thus, functional composition (the left-hand side in the above equation) is defined in terms of functional application (the right-hand term of the equation). Where _f_:_X![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)Y_, we sometimes use applicative notation assigned to the whole set _X, f_(_X_), to represent the set (contained in _Y_) of all values _f_(_x_) of arguments _x_ in _X. f_(_X_) is the _image_ of _X_ under the function _f_.

The two central notions of the calculus are the _derivative,_ which represents the instantaneous rate of change of a function at a given point, and the _integral,_ which allows for an exact calculation of the portion of a space (e.g., an area or volume) determined (bounded) by a given function. Modern foundational studies have now shown that "set" (deriving from the loci of Euclidean geometry) and "function" (deriving from the calculus) are the two most fundamental notions of mathematics.

**2.1 The Arithmetization of Analysis**

In the development of analysis during the years immediately following Newton and Leibniz, geometrical ideas tended to predominate over purely algebraic notions. This was due in part to the retrospective realization that Newton's limit operation had already been successfully used in special cases by the Greek mathematician Archimedes (third century B.C.), whose "method of exhaustion" had led him to calculate correctly certain geometrical limits. However, the analytic work of L. Euler, K. Gauss, A. Cauchy, B. Riemann, and others led to a shift towards the predominance of algebraic and arithmetic ideas. In the late nineteenth century, this tendency culminated in the so-called arithmetization of analysis, due principally to K. Weierstrass, G. Cantor, and R. Dedekind.

Weierstrass developed the theory of _real functions,_ that is, functions _f_:**_R![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)R_**, and, among other things, furnished the first example of a real function that is everywhere continuous (the geometrical graph of the function has no breaks) but nowhere differentiable (the instantaneous rate of change of the function does not exist at any point). In an impressive series of papers, Cantor elaborated the theory of infinite sets, including transfinite cardinal and ordinal numbers. In particular, he showed that there were different orders or levels of infinity (see below) the lowest level being that of the natural numbers **_N_**, which he called _denumerable infinity._ However, it was Dedekind who brought the work of Weierstrass and Cantor to completion by giving abstract, axiomatic characterizations of each of the major number systems in his landmark work _Was Sind und Was Sollen die Zahlen?_ (188), thereby establishing definitively that mathematical analysis was logically independent of geometry. Of course, geometrical ideas were and are always present and available via Descartes' correspondence between geometry and algebra, but Dedekind's work showed that, though convenient and intuitively useful, these ideas were in no wise logically necessary to the development of analysis. We begin with a sketch of Dedekind's construction and characterization of the natural numbers **_N_.**

**3.3 Dedekind and the Axiomatization of Arithmetic**

Already in the seventeenth century, Galileo had noticed that infinite sets like the natural numbers admit functions into themselves that are _injective_ (one-to-one) without being _surjective_ (onto). For example, the function 2_n_**: _N![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)N_**, which associates with each natural number n its double 2_n_, constitutes a _bijective_ (one-to-one and onto) correspondence between the set **_N_**and the proper subset of all even numbers 2**_N_**, where 0 ![](https://bahai-library.com/images/h/hatcher_foundations_Image93.gif) 0, 1 ![](https://bahai-library.com/images/h/hatcher_foundations_Image93.gif) 2, 3 ![](https://bahai-library.com/images/h/hatcher_foundations_Image93.gif) 6, etc. However, it is easy to prove by mathematical induction that no finite set has this property. More precisely, every injection _f_:_X![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)X_ of a finite set _X_ into itself must also be surjective, that is, _f_(_X_) = _X_ (every element _x f X_ is of the form _x = f_(_y_) for some _y_ in _X_), and thus bijective. Dedekind saw that this provided an intrinsic definition of an infinite set. Accordingly, a set _X_ is said to be _(Dedekind-)infinite_ if there exists some injective function _f_:_X![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)X_ that is not surjective.

Dedekind's treatment of the natural numbers begins by observing that the system of natural numbers (**_N_**, 0, ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)), where ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif): **_N![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)N_** is the _successor function_ defined by ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)(_n_) = _n_+1, is Dedekind-infinite because ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)is injective but not surjective. Indeed, ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)(_n_) = ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)(_m_) only if _n = m_, and 0 is not a successor of any natural number (and is, in fact, the only nonsuccessor). By an ingenious construction, Dedekind showed that any Dedekind-infinite set contains the system  
(**_N_**, 0, ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)) as a subsystem. He furthermore showed that the system (**_N_**, 0, ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)) is completely determined (axiomatically characterized) by three axioms now known as the _Peano axioms_ (though G. Peano published them only in 1889 and later acknowledged that he had taken them from Dedekind's 1888 work). We use Peano's symbol '![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif)' to represent the relationship between an object x and a set _X_ of which it is a member. Thus, where **_N_** is a nonempty set, 0 ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif)**_N_** and ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif):**_N![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)N_**, the Peano axioms are as follows: (1) 0 ![](https://bahai-library.com/images/h/hatcher_foundations_Image94b.gif)![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)(**_N_**); 0 is not a successor; (2) ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)(_n_)=![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)(_m_) implies _n = m_; ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif) is injective; (3) If _X_ is an inductive subset of **_N_** then _X = **N**_ (a subset _X_ of **_N_**, symbolized ![](https://bahai-library.com/images/h/hatcher_foundations_Image71.gif)**_N_,** is inductive if 0 ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif) _X_ and if _X_ is invariant under ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif), ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif) (_X_)![](https://bahai-library.com/images/h/hatcher_foundations_Image71.gif)_X_). In other words, **_N_** is the smallest inductive set.

Using the technique of _recursive definition_ Dedekind also showed how all the usual operations of arithmetic could be uniquely defined in terms of 0 and ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif). For example, addition + is the unique binary operation on **_N_** that satisfies the two recursion equations (i) _n_ \+ 0 = 0 and (ii) _n_ \+ ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)(_m_) = ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)(_n_ + _m_). Similarly, multiplication ![](https://bahai-library.com/images/h/hatcher_foundations_Image96b.gif) is the unique binary operation satisfying the two recursion equations (i') _n ![](https://bahai-library.com/images/h/hatcher_foundations_Image96b.gif)_ 0 = 0 and (ii') _n ![](https://bahai-library.com/images/h/hatcher_foundations_Image96b.gif)![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)_ (_m_) = (n ![](https://bahai-library.com/images/h/hatcher_foundations_Image96b.gif) m) + _n_.

Definition by recursion equations not only provides a complete logical definition of the operation in question, but also gives an algorithm for computing its values. For example, by repeated application of equations (i) and (ii), we can determine that 3 + 5 = 8. Moreover, all of the usual laws of these operations (e.g., the commutative law of addition, _n_ \+ _m = m_ \+ _n_) can be logically deduced from the recursive definitions and the three Peano axioms. Finally, the relation '![](https://bahai-library.com/images/h/hatcher_foundations_Image99.gif) ' of 'greater than' between natural numbers a and b can be defined in terms of addition: b ![](https://bahai-library.com/images/h/hatcher_foundations_Image99.gif)a if and only if _a_ + _n_ = _b_ from some nonzero _n ![](https://bahai-library.com/images/h/hatcher_foundations_Image74.gif)**N**_.

Thus, in one sweep, Dedekind gave both an axiomatic characterization of the natural numbers and a method of constructing them, if given the existence of any Dedekind-infinite set. He showed further that any set of recursion equations, such as those for addition and multiplication above, are a special case of a single recursion scheme, called _simple recursion_, which can be stated as follows: Given any nonempty set **_S_**, any designated element _a ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif)**S**_, and any function _f_:**_S![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)S_**, then there exists one and only one function _h_: _**N![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)S**_ such that _h_(0) = _a_ and _h_(![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)(_n_)) = _f_(_h_(_n_)). Moreover, the proof of the simple recursion scheme uses only the three Peano axioms (and each is necessary to the proof).

In order to understand the import of this result, we introduce some modern terminology. A function _f:S![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)**S**_, from a nonempty set **_S_** into itself, is now called a _(discrete) dynamical system_. Beginning with any element _a ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif) S_ as an initial value, we can _iterate_ the application of the function _f_ applied to _a_, obtaining the sequence of values _a_, _f_(_a_), _f_(_f_(_a_)), . . . , _f_(. . .(_f_(_f_(_a_))). . .), . . . , called the _orbit_ of a under _f_. The study of the orbits of elements of a dynamical system has become a major tool in modern analysis. If we introduce the notation _f n_(_a_) for the nth iterate of f applied to a, then the orbit of a is precisely the sequence _a_ = _f0_(_a_), _f1_(_a_), _f2_(_a_), . . ., _f n_(_a_) = _h_(_n_), . . ., where _h_:**_N![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)S_** is the unique function whose existence is guaranteed by Dedekind's scheme of simple recursion.

In other words, the natural numbers **_N_** together with the successor function ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif), constitute a universal dynamical system generated by the single element 0: The axiom of induction tells us that the set **_N_** is precisely the orbit of 0 under ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif), and the theorem of simple recursion tells us that any orbit _f n_(_a_) of any element a in any dynamical system _f_:**_S![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)S_** is the "image" of the orbit **_N_** of 0 by a unique function _h_:**_N![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)S_**, _h_(_n_) =_f n_(_a_) for all _n ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif)**N**_**.**

It is now known that any such "universal system" is unique up to isomorphism, meaning that the structure of the system is unique, though the particular set of objects on which we define the structure may vary. Since the universality of such systems resides in their structure, we will henceforth speak of universal structures.

The general theorem on the existence (and uniqueness) of universal structures was formulated and proved only in the mid-twentieth century ‚Äî essentially by the Bourbaki group of French mathematicians and the American P. Freyd ‚Äî but Dedekind did explicitly establish the existence and uniqueness theorem for the case of the universal structure (_N_, _0_, ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)). (The work of the American G. Birkhoff in the 1930s also contributed to the achievement of the general theorem on universal structures.)

In proving the scheme of simple recursion using only the Peano axioms, Dedekind therefore proved that any model of the Peano axioms is a universal dynamical system. The converse result, namely, that any universal dynamical system satisfies the Peano axioms, is also true (without any prior assumption of the existence of an infinite set) but was only explicitly proved in the early 1960s by F. W. Lawvere. Putting this latter result together with those of Dedekind, we now have what might be called the "fundamental theorem" or "core theorem" of modern foundations:

_The existence of an infinite set, the existence of a (necessarily unique) model of the Peano axioms, and the existence of a (necessarily unique) universal dynamical system are all logically equivalent (the existence of any one of these entities implies the existence of the others)._

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

**Figure 4. The Natural Numbers as a Universal Dynamical System**  
![](https://bahai-library.com/images/h/hatcher_foundations_figure4.gif)

The given functions ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif):**_N![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)N_**and _f_:**_S![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)S_** are represented by solid arrows, while the function _h_ whose unique existence is derived from these data is represented by the broken-bodied arrows. The resulting diagram is said to be commutative, meaning that every way of composing one arrow with another yields an equality. Thus, where '![](https://bahai-library.com/images/h/hatcher_foundations_Image95.gif)' represents the operation of functional composition (see above), the equalities _h![](https://bahai-library.com/images/h/hatcher_foundations_Image95.gif)_0 = _a_ and _h![](https://bahai-library.com/images/h/hatcher_foundations_Image95.gif)![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)_= _f![](https://bahai-library.com/images/h/hatcher_foundations_Image95.gif)h_ hold. (Here, the element 0 of **_N_** is represented as the target of a function from a one-element set **1** to **_N_**, and the element a of **_S_** is represented in a similar way.) These equalities are just the two recursion equations of the scheme of simple recursion: _h_(0) = _a_ and _h_(![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)(_n_)) = _f_(_h_(_n_)), for all _n_ in **_N_**.

We say that _h_ is a morphism from the structure (**_N_**, 0, ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)) to the similar structure (**_S_**, _a_, _f_) (see below). The existence and uniqueness of the morphism h from (**_N_**, 0, ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)) to any similar structure (**_S_**, _a_, _f_) is the mark of the universality of the structure (**_N_**, 0, ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)).

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

  
  
This fundamental result has many consequences. It means, for example, that it is not necessary to answer the age-old philosophical question "what is a natural number" in order to do mathematics. One only has to establish the existence of some system satisfying the Peano axioms. However, it also means that classical mathematics is based squarely on the existence of infinite sets.

Once the axiomatization of the system **_N_** of natural numbers was accomplished, an axiomatic characterization of the other major number systems followed with relative ease, as Dedekind himself showed. Using modern terminology, these characterizations are as follows.

A _ring_ is an algebraic system that it is closed under addition, subtraction, and multiplication (but not necessarily division). A ring is _ordered_ if it has a relation of 'greater than', symbolized by '![](https://bahai-library.com/images/h/hatcher_foundations_Image99.gif)', with 1>0, _b![](https://bahai-library.com/images/h/hatcher_foundations_Image99.gif)a_ if and only if _b_-_a![](https://bahai-library.com/images/h/hatcher_foundations_Image99.gif)_0, and such that the positive elements (those greater than 0) are closed under addition and multiplication. An ordered ring is _well-ordered_ if every nonempty subset of its positive elements has a (necessarily unique) smallest element. Then, the (positive and negative) integers **_Z_** form the unique (up to isomorphism) well-ordered ring.

Recall that a field (see above) is a ring that is also closed under division by nonzero elements. Then, the system **_Q_** of rational numbers is the unique (up to isomorphism) smallest ordered field.

An ordered field is _complete_ if every nonempty set _X_ of its elements that is _bounded above_ (there is some element of the field that is greater than or equal to every element in _X_) has a smallest upper bound. Then, the system _**R**_ of real numbers is the unique (up to isomorphism) complete, ordered field.

Using ideas of P. Erd√∂s, L. Gillman, M. Henrikson, and H. J. Keisler, W. S. Hatcher succeeded (in 1980) in giving an algebraic axiomatic characterization of the so-called minimal ultrapower model of Leibniz' hyperreal number field **_R_**\* (however Hatcher's characterization does assume Cantor's _continuum hypothesis,_ _CH_, discussed below).

**3.4 Frege's System and the Paradoxes**

Dedekind's axiomatic characterizations of the major number systems accomplished for analysis what Euclid had accomplished for geometry some two thousand years earlier. Yet, Dedekind's results raised new questions even as they answered old ones: (1) Is the assumption of the existence of an infinite set ‚Äî so necessary to Dedekind's constructions ‚Äî logically justified? Can we actually prove that an infinite set exists and, if so, on what basis? (2) Dedekind's constructions involve Cantor's infinitary set operations (such as infinite set unions and intersections). Are these legitimate? Can the general rules for operating with arbitrary sets be codified and axiomatized? (3) Surely, there must be some limits to the ever increasing generality and abstraction of mathematics. What are these limits? How indeed can we be certain that mathematics (in particular, infinite mathematics) is logically consistent? (4) Can we in fact axiomatize all of mathematics in one system?

In his _Grundgesetze der Arithmetik,_ published in 1893, G. Frege attempted to provide a positive answer to all of these questions by presenting a formal axiomatic system for the whole of mathematics. In modern terminology, the essentials of Frege's system are as follows. Formula and set (collection of objects satisfying a formula) are the basic notions of mathematics. The basic relationship of all mathematics is the relationship '![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif)' between an object x and a set y of which it is a member. Thus, the basic formulas of mathematics have the form '_x ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif) y_', where x and y are variables. The general formulas are built up from basic formulas by the logical propositional connectives 'or', 'and', 'not', 'if . . . then - - -', '. . . if and only if - - -', and the quantifiers 'there exists' and 'for all'. The language is thus a first-order language, and the logical rules are those of first-order logic (see above).

The specific principles (axioms) of Frege's system are extensionality, which asserts that sets with the same elements are equal, and comprehension, which asserts that every formula _F_(_x_) determines a set w whose elements are exactly those objects satisfying the formula, that is, _x ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif) w_ if and only if _F_(_x_), for all _x_. The set w is often symbolized as {_x_ : _F_(_x_)}, "the set of all x such that _F_(_x_)." In that case, the comprehension principle can be symbolically rendered as _x ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif)_ {_x : F_(_x_)}![](https://bahai-library.com/images/h/hatcher_foundations_Image100.gif)_F_(_x_), where the double arrow symbolizes 'if and only if'. Both the extensionality and comprehension principles were (and are) extensively used in mathematics and regarded as intuitively natural.

Based only on these principles, Frege constructs a system (**_N_**, 0, ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)) satisfying the Peano axioms. Frege first defines the empty set ![](https://bahai-library.com/images/h/hatcher_foundations_Image101b.gif) as the set determined by any contradictory formula (e.g., _x ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif) x_ and _x ![](https://bahai-library.com/images/h/hatcher_foundations_Image94b.gif) x_). Then, 0 is defined as the set {![](https://bahai-library.com/images/h/hatcher_foundations_Image101b.gif)} whose only element is ![](https://bahai-library.com/images/h/hatcher_foundations_Image101b.gif) (0 is thus the set of all empty sets), 1 is the set of all singletons {_x_}, 2 the set of all doubletons {_x,y_}, etc.  
The successor ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)(_x_) of a natural number (in fact of any set) is defined by comprehension as the set of all sets y such that _y_\* ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif)_x_, where _y_\* is the result of removing any single element from _y_. An inductive set is then defined as a set having 0 as an element and also the successor of any element it contains. **_N_** is now definable as the intersection of all inductive sets, and the Peano axioms are provable, thereby establishing that **_N_** is an infinite set.

Frege's method and approach were ingenious but, as Bertrand Russell discovered in 1902, Frege's system is logically contradictory. To deduce formally a contradiction in this system, we need only take the formula _x ![](https://bahai-library.com/images/h/hatcher_foundations_Image94b.gif) x_ and apply the comprehension scheme to obtain a set w whose elements are exactly those which satisfy this formula. Thus, _x ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif) w_  if and only if _x ![](https://bahai-library.com/images/h/hatcher_foundations_Image94b.gif) x._ But since this holds for all sets _x_, it holds in particular for w, giving the contradiction _w ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif) w_  if and only if _w ![](https://bahai-library.com/images/h/hatcher_foundations_Image94b.gif) w_. This contradiction is known as 'Russell's paradox', and it shows that {_x_ : _x ![](https://bahai-library.com/images/h/hatcher_foundations_Image94b.gif) x_}, "the set of all sets _x_ not elements of themselves," is a contradictory notion.

Russell's paradox sent a shock wave through the mathematical and philosophical community of the day. In particular, the failure of Frege's system showed that there are indeed limits to mathematical/logical generality and that the intuitive naturalness of a principle like comprehension is not a sufficient guarantee against logical error. The basic problem of foundations thus became that of finding a coherent method of distinguishing between legitimate and illegitimate uses of the comprehension principle. To that end, two new systems were propounded in 1908, one by E. Zermelo and the other by Russell himself.

**3.5 Type Theory and Set Theory**

Russell's theory of types considers that all sets are built up from individuals, which are defined as abstract, simple entities (i.e., entities devoid of any complexity). Individuals are declared to be of type 0, sets of individuals of type 1, sets of sets of individuals of type 2, and, generally, entities of type _n_+1 are sets whose elements are all of type n. The language of type theory is more restrictive than the language of Frege's system, because now basic formulas have the form _xn![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif) yn+_1, where _xn_and _yn+_1are variables of types _n_ and _n_+1 respectively. Other formulas are built up from basic formulas by the usual propositional connectives and the quantifiers applied to typed variables. We say that the formulas of type theory are stratified.

The logical rules of type theory are appropriate generalizations of the rules for first-order logic. (In fact, type theory can be given a first-order formulation.) The specific axioms of type theory are just the two principles of extensionality and comprehension, formulated within the language of type theory. Russell's paradox is avoided because the troublesome formula _x![](https://bahai-library.com/images/h/hatcher_foundations_Image94b.gif) x_  is not stratified and thus not a part of the language. Frege's construction of the system (**_N_**, 0, ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)) can be carried through in type theory because any set _x_ and its successor ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)(_x_) are of the same type. Moreover, the first and third Peano axioms can be proved. However, because of the type restrictions on the formulas of the language, the theorem of infinity can no longer be proved and must now be added as an explicit axiom. In fact, the form Russell chose for the axiom of infinity was precisely the second Peano axiom, which asserts that the successor function ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif) is injective, and thus implies (in conjunction with the first Peano axiom) that **_N_** is infinite.

Russell's system of type theory (which we have presented here in a somewhat simplified form) was clearly an attempt to salvage as much as possible of Frege's approach to foundations. However, in its final form type theory confronts us with a dilemma. The system is clearly (and provably) consistent without the axiom of infinity, but in that form it does not provide an adequate basis for infinite mathematics. A flexible and natural foundation for mathematics does result when we add an axiom of infinity, but now the infinity postulate acquires a somewhat _ad hoc_ character losing thereby some of its logical justification. In particular, we have not derived the natural numbers from any more fundamental intuition, because the postulation of infinity is already equivalent to the existence of the natural numbers according to Dedekind's core result.

A liberalized version of type theory, called New Foundations, was devised by the American logician W. V. Quine in 1937. It requires that the formulas F(x) of the comprehension axiom be stratified but otherwise allows general (nonstratified) formulas in the language. It was shown in the 1950s by E. Specker and N. Goodman that the principle of infinity is provable in Quine's system. In itself this is a positive result, but a number of anomalies and bizarre features of New Foundations continue to appear, making it perhaps the most controversial of all foundational systems. The current consensus seems to be that the system is most probably free from formal contradiction but too unnatural to be considered a satisfactory foundation for mathematics. It allows for the generation of analysis and for most of the central principles of classical mathematics but also generates a number of principles and properties that do not occur in the usual practice of mathematics.

E. Zermelo's axiomatic theory of sets also appeared in 1908. It was initially presented as a straightforward codification of the most useful and generally accepted instances of the comprehension principle (essentially, G. Cantor's intuitively defined set operations). The original system had some defects and limitations that were eventually corrected and removed by A. Fraenkel, T. Skolem, J. von Neumann, A. Mostowski, A. Morse, and J. Kelley. However, in the system's most definitive version, the dominant ideas are those of von Neumann. We will present the system in its most complete form as a _class/set_ theory.

In class/set theory, mathematical entities are considered to constitute a hierarchy, but a much more flexible one than in Russell's type theory. At the bottom of the hierarchy are simple objects, called atoms, which have no elements whatever, but which can themselves be elements of composite entities, called classes.

The language of class/set theory is almost the same as Frege's: basic formulas have the form _x ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif) y_ or _At_(_x_) ('_x_ is an atom'), and general formulas are built up using the propositional connectives and quantifiers. Thus, the underlying logic of class/set theory is first-order logic. A class _x_, symbolized _Cl_(_x_), is any non-atom: _Cl_(_x_) ![](https://bahai-library.com/images/h/hatcher_foundations_Image100.gif)![](https://bahai-library.com/images/h/hatcher_foundations_Image102.gif)_At_(_x_), where '![](https://bahai-library.com/images/h/hatcher_foundations_Image102.gif)' is the symbol for 'not'. Frege's principle of extensionality holds for classes but not for atoms. Thus, there can be many atoms, but exactly one no-element class, the null class ![](https://bahai-library.com/images/h/hatcher_foundations_Image101b.gif), classes being determined by their elements. Moreover, every atom occurs as an element of at least one class. Thus, formally, an atom can occur on the left  
of the '![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif)' sign but never on the right.

The classes are themselves divided into two further categories called sets and proper classes (nonsets). A set is a class (thus, not an atom) that occurs as an element of at least one other class, whereas a proper class is one that, while having elements, is never itself an element. Thus, formally, sets can occur on either side of the '![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif)' sign, while proper classes can occur only on the right of '![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif)'. If we define the predicate '_Sat_(_x_)' to mean 'x is an atom or a set', then we have the principle: '_x ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif) y_ only if _Sat_(_x_) AND _Cl_(_y_)', that is, 'only atoms and sets are members and only classes have members'. The distinction between atoms and classes is already contained in Zermelo's 1908 paper, but the distinction between sets and classes originates with von Neumann in 1925.

In class/set theory, the criterion that distinguishes proper classes from sets is size: any proper class is bigger than every set. Thus, proper classes are collections that are too large to be considered as a single entity and thus as a component (element) of another entity.

There is a suggestive analogy between the ontology of class/set theory and the ontology of modern physics, in which the atoms of class/set theory correspond to elementary particles, sets correspond to macro-objects, and proper classes correspond to macro-physical systems (e.g., galaxies) composed of many, possibly disparate, objects. It is not clear whether von Neumann (who made major contributions to theoretical physics) ever had such an analogy in mind.

Besides positing the extensionality principle, which holds for classes but not for atoms, class/set theory posits a comprehension scheme that holds for classes but not for sets: Given any formula _F_(_x_) of the language of class/set theory, there exists the class w of all sets or atoms x such that x ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif) w if and only if _F_(_x_). Letting _w_ = {_x_ : _F_(_x_)} as in the above, we thus have _x![](https://bahai-library.com/images/h/hatcher_foundations_Image74.gif)_{_x_ : _F_(_x_)} ![](https://bahai-library.com/images/h/hatcher_foundations_Image100.gif)_F_(_x_) AND_Sat_(_x_). An attempt to deduce Russell's paradox now only yields the result that {_x_ : _x ![](https://bahai-library.com/images/h/hatcher_foundations_Image94b.gif) x_} is a proper class (i.e., not a set).

The remaining axioms of class/set theory affirm that the null class is a set, posit the existence of an infinite set, and establish several basic ways of generating new sets from existing sets. The axiom of pairing allows the formation of the doubleton set {_x_,_y_} whose elements are any two given sets _x_ and _y_. The axiom of separation says that the intersection (common part) _x ![](https://bahai-library.com/images/h/hatcher_foundations_Image103b.gif) y_ of a set _x_ and a class _y_ is always a set. The operation of (infinite) union is defined with respect to a given function _f_: _x![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)y_, where _x_ is a set. In this case, union affirms that the class {_z_ : _z ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif) f_(_k_) for some _k ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif) x_} is a set. Furthermore, the image _f_(_x_) = {_z_ : _z_ = _f_(_k_) for some _k ![](https://bahai-library.com/images/h/hatcher_foundations_Image74b.gif) x_} is declared to be a set. Combining union with pairing immediately yields the fact that any finite class is a set. The powerset _P_(_x_) of any set _x_ is the class of all subsets of _x_. Finally, there is a restriction axiom which asserts, in effect, that all sets are built up from atoms and the empty set ![](https://bahai-library.com/images/h/hatcher_foundations_Image101b.gif) by (an unlimited number of) iterations of the powerset and union operations.

A theorem of Cantor establishes that the powerset **_P_**(_x_) of any set x has greater cardinality (more elements) than _x_. Thus, by iterating powerset, we can create sets of greater and greater cardinality. In particular, starting with the infinite set whose existence is postulated by the axiom of infinity, we can create sets of increasingly greater infinite cardinality. This yields Cantor's hierarchy of transfinite numbers.

The union operation allows us to create many different sets by forming all possible collections of the sets that exist. As we iterate powerset and union, we therefore progressively create bigger sets and more sets. The universe (proper class) _V_ = {_x_:_x_ = x} of all sets and atoms therefore grows both upward and outward as we iterate powerset and union. This is often illustrated "geometrically" as follows.

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

**The Universe _V_ of all Sets of Class/Set Theory**

The shape of the universe of sets depends in part on how many atoms are assumed to exist. In the case where no atoms at all are postulated, we have a theory of pure sets in which the only no-element entity is the null set.

**Figure 5. The Universe _V_ of Well-Founded Sets**

![](https://bahai-library.com/images/h/hatcher_foundations_figure5.gif)

In the universe of pure sets, all sets are built up from the null set by alternated iterations of powerset and union. Thus, after taking the union _D_ of all the sets ![](https://bahai-library.com/images/h/hatcher_foundations_Image101b.gif), **_P_**(![](https://bahai-library.com/images/h/hatcher_foundations_Image101b.gif)), . . . , **_P_**( . . . (**_P_**(![](https://bahai-library.com/images/h/hatcher_foundations_Image101b.gif))) . . .), . . ., we will continue with iterations of the powerset applied to D, thereby generating the hierarchy _D_, **P**(_D_), . . . , **_P_**( . . . (**_P_**(_D_)) . . .), . . ., which will, again, be united into a set _D_', etc., _ad infinitum._ The universe _V_ of sets is the proper class of all sets generated in this manner. Powerset generates increasingly bigger sets (augmenting the "height" of the universe), whereas union generates more and more sets (augmenting thereby the "width" of _V_).

The universe _V_ of sets obtained in this manner is said to be _well-founded,_ meaning that _V_ has a bottom (a beginning point) but no top (no highest or final point). The well-foundedness feature of _V_ is due to von Neumann's axiom of restriction, and establishes a strong analogy between the universe of sets and the physical universe, which, according to modern quantum theory, has irreducible, smallest elements (elementary particles) but no apparent limit to the ultimate complexity of systems that can be formed by combinations of elementary particles.

If we assume the existence of atoms, then we "widen the base" of the universe without changing its fundamental structure. This gives the following shape to _V_:

**Figure 6. Shape of the Universe _V_ with Upward and Outward Growth**

![](https://bahai-library.com/images/h/hatcher_foundations_figure6.gif)

The atoms _a_,_b_, _c_, . . . and the null set ![](https://bahai-library.com/images/h/hatcher_foundations_Image101b.gif) represent the lowest level (the "bottom") of the universe. The next level will be sets having as elements only those objects of the lowest level, and so on with alternated iterations of powerset and union as before.

The universe of pure sets is sufficient as a foundation for pure mathematics, but it is sometimes quite convenient to have atoms in the universe.

Without the axiom of restriction, the universe _V_ could be thought of as both infinitely descending and infinitely ascending. Such _anti-founded_ universes have been studied by the logicians P. Aczel, J. Barwise, and J. Etchemendy.

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

The lavish existence assumptions of class/set theory certainly provide a rich theory in which to carry on mathematics. For example, since the existence of an infinite set is explicitly postulated, one can directly implement Dedekind's original construction of the natural numbers and prove the Peano axioms. Or, following von Neumann, one can use the operations of set theory to construct a privleged model (**_N_**, 0, ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)) of the Peano axioms. 0 is the null set ![](https://bahai-library.com/images/h/hatcher_foundations_Image101b.gif) and the successor ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)(_x_) of any set _x_ is the _self-adjunction_ of _x_, ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)(_x_) = _x ![](https://bahai-library.com/images/h/hatcher_foundations_Image104b.gif)_ {_x_} (the union of _x_ with {_x_}), which amounts to adjoining the entity (set) _x_ to the collection _x._ Thus defined, ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)(_x_) is always different from _x_ since, as a consequence of the axiom of restriction, _x![](https://bahai-library.com/images/h/hatcher_foundations_Image74.gif)x_ never holds in class/set theory.

Except for the axioms of extensionality and restriction, each of the other axioms of class/set theory is a particular case of Frege's comprehension scheme. However, for the full development of mathematics, a further axiom is needed, the _axiom of choice,_ which states that an infinite choice is always possible, even when no formula or rule for making the choice is given. In 1953, E. Specker showed that the negation of the axiom of choice is deducible in Quine's system of New Foundations (see above). Since the axioms of New Foundations are only extensionality and comprehension for stratified formulas, Specker's result shows that Frege's system would have been inadequate as a foundation for all of mathematics even if it had been consistent.

Note that there is an obvious model of type theory within class/set theory. The individuals (entities of type 0) of type theory are interpreted as the von Neumann natural numbers _**N**_**.** Entities of type 1 are then elements of **_P_**(**_N_**), entities of type 2 elements of **_P_**(**_P_**(**_N_**)), and so on. Thus, the axioms of type theory are all true when appropriately interpreted in the hierarchy **_N_**, **_P_**(**_N_**), . . . , **_P_**( . . . (**_P_**(**_N_**)) . . .), . . . , of class/set theory.

**3.6 Foundational Aspects of Class/Set Theory**

Ever since Cantor's development of the theory of infinite sets and transfinite numbers, set theory has been regarded as a legitimate mathematical theory in its own right. Evaluating class/set theory as a foundation for mathematics is a more difficult matter. On one hand, the _ad hoc_ postulation of infinity makes it difficult, if not impossible, to consider class/set theory as a logical justification for infinite mathematics. Indeed, as a foundation, the whole of class/set theory has a certain _ad hoc_ character, since it is essentially a straightforward codification of those principles that are perceived by most mathematicians as necessary for mathematics.

On the other hand, class/set theory does not appear to generate any principles that are shocking or unacceptable to mathematicians; whereas other systems in which a theorem of infinity is provable (e.g., Quine's system of New Foundations discussed above) do generate various unacceptable results along with the acceptable ones. The experience of several generations of mathematicians with set theory has restored a certain confidence in infinite mathematics, and the principles of class/set theory have come to be viewed generally (but not universally) as intuitively natural. However, various other foundational limitations of class/set theory have appeared.

In 1931, K. G√∂del employed an ingenious argument which, as slightly improved by J. B. Rosser, establishes that any consistent, recursively axiomatic system _**S**_ adequate for Peano arithmetic (and thus, in particular, any foundational system **_S_**) must contain an infinity of _undecidable_ propositions _p_, that is, propositions in the language _L_ of **_S_** such that neither p nor its negation not-_p_ is a theorem of **_S_**. (A _recursively axiomatic_ system is one whose set of axioms can be determined by an algorithm \[see above\]. All known foundational systems have this property.) Since either _p_ or not-_p_ must be true under any interpretation of a system, G√∂del's result means that if class/set theory is consistent, then there are infinitely many true statements in the language of the theory that cannot be proved from its axioms (and that this will continue to hold even if any finite number of new axioms be added to the system).

This result sent a second wave of shock through the mathematical community, just as the recovery from the initial shock of Russell's paradox seemed complete. However, the undecidable propositions actually exhibited by G√∂del's construction appeared rather contrived and artificial, thus minimizing the initial concern about "lost truths" of mathematics.

Nevertheless, from the beginning of Cantorian set theory in the late nineteenth century, there were several fundamental propositions that had resisted all efforts either of proof or of disproof. Perhaps the most significant was Cantor's continuum hypothesis. According to Cantor's theorem (see above) the cardinality of the natural numbers **_N_** is strictly less than the cardinality of its powerset _**P**(**N**_). It was also established that the cardinality of the real numbers _**R**_ (sometimes called the continuum) was the same as _**P**(**N**_). The question then arose as to whether or not there are sets whose cardinality is strictly intermediate between the cardinalities of **_N_** and **_R_**. Cantor himself hypothesized that there were none and called this proposition the continuum hypothesis, abbreviated _CH_. In 1963, P. Cohen proved that _CH_ was an undecidable proposition of class/set theory (provided that the latter is consistent). Cohen also proved that the axiom of choice was independent of the other axioms of class/set theory.

The independence of the choice axiom can be viewed as nothing more than a proof of the efficiency of the axiomatization of set theory, because there is general agreement that choice is an intuitively valid principle of mathematics. But there is no comparable consensus regarding _CH_ (other than the observation that the assumption of _CH_ considerably simplifies the theory of cardinal numbers). Subsequent to Cohen's result, and using his method of _forcing,_ a number of other undecidable propositions of class/set theory have been discovered. This plethora of independent results shows conclusively that the truths of mathematics are underdetermined by the axioms of class/set theory, provided these latter are consistent.

The necessity for the _ad hoc_ postulation of infinity in both type theory and set theory, and the consequent failure to derive infinite mathematics from any more fundamental logical intuition, raised the question of the consistency of these theories in a particularly sharp way. That a contradiction has not in fact been derived in these systems is not in itself a guarantee of consistency. For example, it would have been logically possible for the contradiction in Frege's system to have remained undiscovered for many years.

In the 1920s, the German mathematician D. Hilbert conceived an ingenious approach to this problem. Hilbert proposed a "program" consisting of a detailed mathematical analysis of the logical structure of the formal system **_S_** of class/set theory with the intention of establishing a rigorous mathematical proof that **_S_** cannot produce a contradiction. Initially such a program appears circular, because it proposes to use mathematics to prove the consistency of mathematics. Hilbert met this objection by proposing to use only finitary mathematics to prove the consistency of infinitary mathematics, pointing out that even though the system of class/set theory contains principles of infinitary mathematics, the formal system itself is a concrete, finitary mathematical object whose language, propositions, axioms, and rules are explicitly and constructively defined.

However, Hilbert's program foundered on K. G√∂del's second fundamental result, which establishes that if a foundational system **_S_** is consistent, then its consistency can be proved only in a stronger system. Indeed, G√∂del's second result shows explicitly how to deduce a formal contradiction "_p_ and not![](https://bahai-library.com/images/h/hatcher_foundations_Image115.gif)-_p_" within any foundational system **_S_**, once given a proof within **_S_** of the consistency of _**S**_. Since infinitary mathematics contains finitary mathematics as a subsystem, one cannot therefore use the latter to prove the consistency of the former, if the former is consistent (recall that anything is provable in a contradictory system).

Our model of type theory within class/set theory (see above), is a proof of the consistency of type theory within class/set theory. Thus, according to G√∂del's second result, class/set theory is strictly stronger than type theory, provided type theory is consistent. It likewise follows from G√∂del's result that we cannot prove the consistency of class/set theory within type theory, provided, again, that type theory is consistent. Thus, the fact that class/set theory has so far produced no intuitively unacceptable or contradictory propositions is, in the final analysis, the only guarantee of its integrity and coherence.

**3.7 Constructivism and Predicativity**

From the beginning of the modern period of foundational study, a certain number of mathematicians have articulated a _constructivist_ conception of mathematics. Though partly based on a negative and skeptical view of infinite mathematics, constructivism is seen by its proponents as a positive and vigorous philosophy of mathematics. Nevertheless, all forms of constructivism propose some kind of restriction on infinite mathematics.

L. Kronecker, H. Poincar√©, L. Brouwer, H. Weyl, and more recently E. Bishop, are among those who have propounded constructivist conceptions of mathematics. However, the leading champion of constructivism was undoubtedly Brouwer, to whom we owe the most comprehensive and thorough exposition of constructivist ideas and principles.

Brouwer held that all attempts to derive mathematics, and the theory of the natural numbers in particular, from some more fundamental or more general logical principle or intuition were mistaken. For him, the intuition of the succession of positive integers, ![](https://bahai-library.com/images/h/hatcher_foundations_Image107b.gif),![](https://bahai-library.com/images/h/hatcher_foundations_Image107b.gif)![](https://bahai-library.com/images/h/hatcher_foundations_Image107b.gif),![](https://bahai-library.com/images/h/hatcher_foundations_Image107b.gif)![](https://bahai-library.com/images/h/hatcher_foundations_Image107b.gif)![](https://bahai-library.com/images/h/hatcher_foundations_Image107b.gif), . . . , conceived as the repetition of an abstract unit " ![](https://bahai-library.com/images/h/hatcher_foundations_Image107b.gif) ", was the ultimate and primary intuition upon which to found mathematics. Although the sequence of natural numbers is _potentially infinite_ because unending, Brouwer held it illegitimate to consider these numbers as constituting a completed whole or set **_N_**, to which further operations, such as the formation of a powerset **_P_**(**_N_**), could be applied. Indeed, Brouwer rejected all of Cantor's infinitary set operations. Thus, Brouwer would accept that the Peano axioms (see above) are clearly true of the natural numbers, but would reject Dedekind's proof of this fact, based as it is on certain principles of infintary mathematics.

Brouwer also rejected some general principles of first-order logic itself, more particularly the classical law of _excluded middle,_ which asserts that any proposition of the form '_p_ or not-_p_' is universally valid (true under any interpretation of _p_). For Brouwer, to assert the truth of a proposition of the form '_p_ or _q_' is to give an explicit proof either of _p_ or of _q_. More generally, Brouwer identified the notion of mathematical truth with the notion of constructive provability. Philosophically, Brouwer's constructivism is thoroughly intuitionistic (see above) and represents a total rejection of mathematical Platonism.

An oversimplified but nonetheless useful approximation of Brouwer's vision of mathematical reality can be obtained from class/set theory by deleting the axioms of infinity and choice and removing the principle of excluded middle from the underlying logic. In such a system, there will still be an infinity of sets, e.g., the sets ![](https://bahai-library.com/images/h/hatcher_foundations_Image101b.gif), **_P_**(![](https://bahai-library.com/images/h/hatcher_foundations_Image101b.gif)), . . . , **_P_**( . . . (**_P_**(![](https://bahai-library.com/images/h/hatcher_foundations_Image101b.gif))) . . .), . . . , but no infinite set. Thus, the individual natural numbers exist but not the set **_N_** whose elements consist of the natural numbers (and nothing else). The other number systems are treated in a similar manner, but considerable portions of classical mathematics are sacrificed in the process. For example, one deals only with the field of _constructive real numbers![](mdash3.gif)_those that can be explicitly approximated by a constructive sequence of rational numbers![](mdash3.gif)and not the classical complete ordered field of Dedekind.

However, because of constructivism's rejection of the Platonic conception of a mathematical universe of stable, nonphysical, and ideal objects, it is more accurate to regard constructive mathematics as a "reality in process of being determined" rather than as a predetermined reality. For example, some laws of Platonic mathematics may fail practically in constructive manipulations of extremely large numbers, even with the use of a high-powered, modern electronic computing system. Consider, for instance, the equation (_E_) (_a+b)-c = (a-c)+b_, which holds between any (Platonic) integers _a_, _b_, and _c_. When _a_ and _b_ are extremely large, the left-hand side of this equation may be practically undefined because the addition algorithm applied to a and b will generate a number too large to be represented in the system, thereby causing it to "overflow." But the calculation may become manageable once a is diminished by c, thus allowing the right-hand side to be computed. Hence, from a purely constructive point of view, the set of values of _a_, _b_, and _c_ for which the equation (_E_) holds is not completely determined but evolves and changes as we build more powerful computers or devise more efficient algorithms.

Though Brouwer and others have been quite vigorous in defense of the constructivist-intuitionist vision of mathematics, their school of thought has gained relatively few adherents. For the majority of mathematicians, constructivism is not infrequently perceived as an attempt to impose an unreasonably restrictive philosophy on mathematical practice rather than to resolve genuine foundational issues. The question can be put quite simply and squarely: if infinite mathematics (including the logical law of excluded middle) is in fact without contradiction, then why should we arbitrarily restrict ourselves to a weaker, emasculated form of mathematics just to satisfy certain essentially philosophical dictates?

However, independent of philosophical issues, it is now generally recognized that constructivism has made positive and genuine contributions to mathematics. For example, a nonconstructive proof of the existence of a certain limit may give us no idea of what the value of the limit actually is; whereas a constructive proof of the same result may furnish an explicit means of calculating an approximate value of the limit. Thus, even though constructive proofs are often more complicated than nonconstructive ones, the extra effort involved in finding a constructive proof is frequently rewarded by extra information about the mathematical object in question.

Because of this extra information usually contained in constructive results, they are regarded as the most genuinely useful part of mathematics by some mathematicians who do not otherwise adhere to a constructivist philosophy of mathematics. This raises the question as to whether all constructive results can be obtained by constructive methods, or whether nonconstructive mathematics is an unavoidable necessity for certain constructive results. Work on this question has provided examples of both extremes: results first obtained by nonconstructive methods but later obtained constructively, and seemingly constructive results for which no known constructive proof has yet been discovered. This suggests that the constructive and nonconstructive aspects of mathematics are delicately intertwined and perhaps cannot be strictly separated in any way that isolates and preserves just the constructive part as an undivided whole.

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

**Constructive Proof vs. Nonconstructive Proof**

It is easy to give examples of rational powers of rational numbers that are themselves irrational. For example 21/2 = ![](https://bahai-library.com/images/h/hatcher_foundations_Image83b.gif), which is irrational. The more difficult question arises: are there irrational powers of irrational numbers that are rational? A positive answer to this question can be given nonconstructively as follows: Consider the number _n_ = ![](https://bahai-library.com/images/h/hatcher_foundations_Image113.gif), which is the irrational number ![](https://bahai-library.com/images/h/hatcher_foundations_Image83b.gif) raised to itself and thus to an irrational power. The number n is either rational or not (principle of excluded middle). If, on the one hand, n is rational, then it is a positive example of an irrational power of an irrational number that is rational. If, on the other hand, _n_ is irrational, then _n![](https://bahai-library.com/images/h/hatcher_foundations_Image83b.gif)_ is, again, an irrational power of an irrational number, but

![](https://bahai-library.com/images/h/hatcher_foundations_image114.gif)

which is rational. Thus, in either case, we have an example of an irrational power of an irrational number that is itself rational.

The nonconstructive nature of this proof is reflected in the use of the principle of excluded middle, and the nonconstructive nature of the result is that we have proved the statement 'either _n_ or n![](https://bahai-library.com/images/h/hatcher_foundations_Image83b.gif) is an irrational power of an irrational number that is rational' without determining which of these two alternatives is in fact the case. One way of giving a constructive proof of this result would be to establish, by a direct argument, either that n is irrational or that n is rational. Such a proof would provide a positive answer to our initial question but also contain the extra information about the rationality or irrationality of _n_.

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

There are some mathematicians who find Brouwer's constructivism too radical but who also have difficulty accepting all of the infinitary principles of class/set theory. As a result, a number of intermediate or "soft constructivist" proposals have been advanced over the years. For example, some propose abandoning just the axiom of choice or else replacing the full choice axiom with various weaker versions (e.g., principles of _denumerable choice_ or _relative choice_ ).

Another proposal, first put forward by H. Poincar√©, would accept the principle of excluded middle, but ban _impredicative definitions_ in which an object m is a member of a set _M_ but is defined only with reference to _M_. Predicative mathematics would accept the axiom of infinity![](mdash3.gif)and thus the existence of such infinite objects as the completed set **_N_** of natural numbers![](mdash3.gif)but would restrict the use made of these objects by disallowing the application of impredicative definitions to them.

It appears from his writings that Poincar√© himself may have supposed that, when once granted the existence of **_N_**, the rest of infinite mathematics could be constructed in a strictly predicative manner. However, this turns out not to be the case. The formation of the powerset **_P_**(_X_) of a given set _X_ is predicative, but Cantor's proof that **_P_**(_X_) has higher cardinality than X is impredicative. Thus, the sequence of sets _**N**, **P**_(**_N_**), . . . , **_P_**( . . . (**_P_**(**_N_**)) . . .), . . . , exists predicatively, but the proof that these sets constitute infinities of progressively higher order is impredicative. Moreover, arbitrary unions are impredicative, and Dedekind's construction of the real numbers **_R_** from the rationals **_Q_** makes unavoidable use of impredicative infinite unions. Thus, not even the real numbers _**R**_ are predicative over the natural numbers **_N_**. Hence, in the last analysis, predicativity appears also as an unnatural, philosophical, nonmathematical limitation on mathematical practice.

**3.8 Combinatory Logic and Category Theory**

Beginning in the 1920s, and continuing for the next decade, the Russian logician M. Sch√∂nfinkel and the American logicians H. B. Curry, A. Church, S. C. Kleene and J. B. Rosser developed an approach to foundations based on 'function' and 'application of a function to its argument' rather than 'set' and 'a set is an element of another set'. The functions of _combinatory logic_ are conceived as operators _f_ that are universally defined and thus applicable to everything, including themselves. Thus, in combinatory logic, _f_(_f_) (the value of the operator _f_ for the argument _f_) is meaningful; whereas in class/set theory, self-application of functions is excluded by von Neumann's axiom of restriction.

However, in 1935, Kleene and Rosser derived a contradiction in combinatory logic similar to Russell's paradox in Frege's system. A revised and weaker version of the system was proved consistent by Church and Rosser, subsequent to which work on combinatory logic was carried on almost exclusively by Curry and his students. However, the Curry school never succeeded in reconstructing a consistent system of combinatory logic sufficiently strong to serve as a foundation for infinite mathematics.

In the early 1960s, there emerged another foundational system based on a generalized notion of function called a 'morphism' or 'map'. _Category theory_ was different from and more flexible than combinatory logic in several ways. To begin with, the basic relationship between morphisms is composition '![](https://bahai-library.com/images/h/hatcher_foundations_Image95.gif)' rather than application. Moreover, the morphisms of category theory are only locally and not universally composable. Indeed, each morphism h is accompanied by an explicit domain _A_ and an explicit codomain _B_, composition between morphisms being defined only when domains and codomains correspond appropriately. Thus, where _h_:_A![](https://bahai-library.com/images/h/hatcher_foundations_Image91b.gif)B_ symbolizes a morphism with domain _A_ and codomain _B_ and _g_:_C![](https://bahai-library.com/images/h/hatcher_foundations_Image91b.gif)D_ a morphism with domain _C_ and codomain _D_, then the composite _g![](https://bahai-library.com/images/h/hatcher_foundations_Image95.gif)h_ will be defined precisely when _B_ = _C_, i.e., when the codomain of _h_ is the domain of _g_.

The analogy between morphisms and functions is obvious. Indeed, if we think of domains and codomains as 'sets endowed with a similar structure' then morphisms can be thought of as 'functions that preserve certain structural features from domain to codomain'. A (concrete) _category_ is then a collection of sets endowed with similar structure, together with a collection, closed under composition, of structure-preserving functions between these sets. (An _abstract category_ has arbitrary objects for domains and codomains and arbitrary relations as morphisms, provided these data satisfy a few fundamental axioms such as compositional closure and the associativity of composition.)

In the initial period of its development, starting with the work of S. Eilenberg and S. MacLane in 1945, the motivation for category theory was more geometric and algebraic than analytic. It was primarily in the 1963 doctoral dissertation of F. W. Lawvere, a student of Eilenberg, that the foundational potential of category theory became apparent. The key notion is that of universal structure (see above), already implicit in Dedekind's characterization of the natural numbers. Lawvere noticed that the system (**_N_**, 0, ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)) of natural numbers could be completely described by the structure-preserving functions _h_:**_N![](https://bahai-library.com/images/h/hatcher_foundations_Image91.gif)S_**, where **_S_** is endowed with a structure (**_S_**, _a_, _f_) similar to the structure (**_N_**, 0, ![](https://bahai-library.com/images/h/hatcher_foundations_Image89b.gif)), and that this description involves only the notion of the composition of functions (see box above). Lawvere then set out to identify and characterize universal mathematics in a similar way that Brouwer had sought to characterize constructive mathematics.

Ingeniously applying the general notion of universal structure formulated and developed by the French school of algebraic geometers, Lawvere succeeded in showing that the heart of classical mathematics, including analysis, was indeed composed of universal systems. For example, Cantor's powerset operation (see above) was reformulated by Lawvere in purely universal terms, as were many other basic notions of set theory. However, in its most general form, Cantor's union operation does not seem to be universal.

Thus, _topos theory_ (which was the name Lawvere gave to the ultimate form of his foundational system) includes the Cantorian hierachy of infinite sets _**N**, **P**_(**_N_**), . . . , **_P_**( . . . (**_P_**(**_N_**)) . . .), . . . , and is much more comprehensive than Brouwer's constructive mathematics, but still does not include all of classical analysis. Interestingly (and surprisingly), the so-called internal logic of toposes turns out to be intuitionistic (the principle of excluded middle does not hold). Thus, looking at mathematics through the prism of universality, intuitionistic logic appears natural rather than arbitrary or forced. This has led some constructivists to embrace topos theory as the golden mean between the perceived excesses of class/set theory on one hand and the ravages of Brouwerian constructivism on the other.

In the last analysis, the foundational power of topos theory turns out to be roughly equivalent to Russell's type theory with an axiom of infinity (which, through the prism of universality, appears more natural and justified) but without the axiom of choice or the principle of excluded middle. However, G. Osius has shown how to add further axioms to topos theory in order to obtain a system equivalent to full class/set theory. An interesting result, due to R. Diaconescu, shows that the addition of the axiom of choice to topos theory immediately implies the principle of excluded middle (and thus that the internal logic is no longer intuitionistic).

In the 1970s, the American logician Dana Scott obtained a set-theoretic model of Curry's combinatory logic by interpreting the functions of combinatory logic as morphisms in a certain category (the category of complete lattices). Subsequent work, in particular by J. Lambek, has shown that combinatory logic is a special case of category theory in which, among other things, all of the morphisms have the same domain and codomain.

Thus, ultimately, the function-theoretic and set-theoretic versions of mathematical reality coincide, even though they represent rather different ways of looking at that reality.

**3.9 The Current Situation: Comparative and Pluralistic Foundations**

The experience of more than a century of modern foundational study has been exciting, frustrating, surprising, rewarding and rather less conclusive than most mathematicians would have liked. On the one hand, it now seems incontrovertible, in the light of G√∂del's undecidability theorems and the plethora of independence results in class/set theory, that the initial goal of establishing a unitary, global foundation for the whole of mathematics is unrealistic. On the other hand, the fact that no contradictions, and indeed no unacceptable principles, have been forthcoming from class/set theory increases our confidence in the coherence and integrity of infinite mathematics.

Moreover, the availability in recent years of extraordinarily powerful electronic computing devices has allowed for an extensive exploration of computer-generated approximations of certain mathematical configurations previously inaccessible to any practical verification. For example, even though the theory of _fractal geometry_ (the geometry of spatial forms which, like some organs of the human body, combine global regularity with local irregularity) is simple and straightforward, it generates extremely complex configurations that can only be effectively represented by computer graphics. It is difficult to imagine that the mathematics of fractals would have developed to the same extent without the availability of computers.

The accumulation of various computer experiences has not yet revealed any significant or fundamental error in mathematical theory. Rather it has shown a remarkable harmony between mathematical theory and mathematical practice. This is, of course, an empirical and relative rather than logical and absolute verification of mathematical theory, but significant nonetheless.

A reverse influence of mathematical computation on theoretical mathematics is also emerging. For example, a recent innovation in and refinement of first-order logic, the _linear logic_ of J.-Y. Girard combines a logic of computation and a logic of proof within a single, unified system. Similarly, the negative solution, by the Russian logician Y. Matiyasevich, of Hilbert's tenth problem (concerning the existence of an algorithm for the solution of diophantine equations) has had an equally significant impact on both computational and theoretical mathematics. Such results show that even in the most established and fundamental parts of mathematics, much remains to be explored and discovered.

The failure to achieve a global and unitary foundation for all of mathematics has led some mathematicians to proclaim the "loss of certainty" or the "loss of truth" in mathematics. However, most mathematicians would regard these as exaggerated reactions and misguided interpretations of the current state of foundational study.

It is more balanced and more realistic to consider that mathematics exists as a body of truths about relationships between abstract entities and structures. These abstract relationships are reflected or instantiated, in various ways and at different levels, in the concrete structures of the physical world. We have no way of acceding directly to this body of truths, and so we approach it from below by inductive generalization, based on analytical observation of empirical reality, and from above by creative conceptualization, based on our synthesized experience of reality as a whole. It is reasonable to assume that there may be any number of consistent and fruitful foundational systems that will generate a significant portion of this body of truths, but no system that will generate all of these truths and nothing else.

Foundational study can thus be viewed as an ongoing, flexible, and pluralistic enterprise of elaborating foundational systems that are then carefully studied, compared, and refined. Our experience has shown that this process invariably leads to new insights into the nature of mathematical truth and the structure of mathematical reality.

**Bibliography.** An excellent reference work that includes reprints of significant articles and materials from all of the major schools of foundational development from 1879 to 1931 is JEAN VAN HEIJENOORT (ed.), _From Frege to G√∂del: A Source Book in Mathematical Logic, 1879-1931_ (1967). For a comprehensive, comparative study of nonconstructive foundations, including a treatment of category theory and G√∂del's theorems, see WILLIAM S. HATCHER, _The Logical Foundations of Mathematics_ (1982). For a more extensive treatment of topos theory than found in this latter reference, see R. GOLDBLATT, _Topoi, The Categorial Analysis of Logic_ (second revised edition, 1984). For intuitionism and constructivism, see A.S. TROELSTRA, _Principles of Intuitionism_ (1969). An excellent treatment of the major logical systems related to foundational study is S. C. KLEENE, _Introduction to Metamathematics_ (1952, reprinted 1971). Finally, RICHARD DEDEKIND, _Essays on the Theory of Numbers_ (1901, reprinted 1963) is still quite accessible, except for some transparently outmoded terminology.